import os
import whisper
from moviepy.editor import VideoFileClip
from concurrent.futures import ProcessPoolExecutor, as_completed
from openpyxl import Workbook
from tqdm import tqdm
import torch
import multiprocessing as mp
import tempfile
import shutil
from pathlib import Path
import gc
import warnings

warnings.filterwarnings("ignore")


def get_optimal_device(device):
    """è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜è®¾å¤‡"""
    if device != "auto":
        return device
    if torch.cuda.is_available():
        return "cuda"
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        return "mps"
    try:
        if torch.version.hip is not None:
            return "cuda"
    except:
        pass
    return "cpu"


def process_single_video(args):
    """å­è¿›ç¨‹æ‰§è¡Œçš„è§†é¢‘è½¬å½•ä»»åŠ¡"""
    video_path, model_size, device, temp_dir = args

    try:
        filename = os.path.basename(video_path)

        process_temp_dir = os.path.join(temp_dir, f"process_{os.getpid()}")
        os.makedirs(process_temp_dir, exist_ok=True)

        audio_path = os.path.join(process_temp_dir, f"{filename}.wav")

        model = whisper.load_model(model_size, device=device)

        with VideoFileClip(video_path) as clip:
            if clip.audio is not None:
                clip.audio.write_audiofile(
                    audio_path,
                    logger=None,
                    verbose=False
                )
            else:
                return (filename, "é”™è¯¯ï¼šè§†é¢‘æ— éŸ³é¢‘è½¨é“")

        result = model.transcribe(
            audio_path,
            language='zh',
            fp16=device != "cpu",
            condition_on_previous_text=False,
            temperature=0.0,
            best_of=1,
            beam_size=1,
            patience=1.0,
            suppress_tokens=[-1],
            no_speech_threshold=0.6,
            logprob_threshold=-1.0,
            compression_ratio_threshold=2.4,
            word_timestamps=False
        )

        text = result['text'].strip()

        if os.path.exists(audio_path):
            os.remove(audio_path)
        if os.path.exists(process_temp_dir):
            shutil.rmtree(process_temp_dir, ignore_errors=True)

        del model
        gc.collect()

        return (filename, text)

    except Exception as e:
        return (os.path.basename(video_path), f"é”™è¯¯ï¼š{str(e)}")


def batch_transcribe_videos(input_folder, output_excel,
                            model_size="large", device="cpu",
                            max_processes=None, chunk_size=None):

    if not os.path.exists(input_folder):
        print(f"âŒ è¾“å…¥æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {input_folder}")
        return

    video_extensions = {'.mp4', '.mov', '.avi', '.mkv', '.flv', '.wmv', '.webm'}
    video_files = [os.path.join(input_folder, f)
                   for f in os.listdir(input_folder)
                   if Path(f).suffix.lower() in video_extensions]

    if not video_files:
        print(f"âŒ æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°è§†é¢‘æ–‡ä»¶: {input_folder}")
        return

    print(f"ğŸ“ æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")

    if max_processes is None:
        max_processes = min(len(video_files), max(1, mp.cpu_count() - 1))

    temp_dir = tempfile.mkdtemp(prefix="video_transcribe_")

    try:
        wb = Workbook()
        ws = wb.active
        ws.append(['è§†é¢‘åç§°', 'è¯†åˆ«ç»“æœ', 'æ–‡ä»¶å¤§å°(MB)', 'å¤„ç†çŠ¶æ€'])

        process_args = []
        for video_path in video_files:
            process_args.append((video_path, model_size, device, temp_dir))

        print(f"ğŸ”„ å¼€å§‹å¤„ç†ï¼Œä½¿ç”¨ {max_processes} ä¸ªè¿›ç¨‹...")

        with ProcessPoolExecutor(max_workers=max_processes) as executor:
            futures = {executor.submit(process_single_video, args): args[0]
                       for args in process_args}

            for future in tqdm(as_completed(futures),
                               total=len(futures),
                               desc="è½¬å½•è¿›åº¦",
                               unit="è§†é¢‘"):
                video_path = futures[future]
                try:
                    filename, text = future.result()
                    file_size = os.path.getsize(video_path) / (1024 * 1024)
                    status = "æˆåŠŸ" if not text.startswith("é”™è¯¯") else "å¤±è´¥"

                    ws.append([filename, text, round(file_size, 2), status])

                    if status == "æˆåŠŸ":
                        print(f"âœ… [å®Œæˆ] {filename}")
                    else:
                        print(f"âŒ [å¤±è´¥] {filename}: {text}")

                except Exception as e:
                    filename = os.path.basename(video_path)
                    error_msg = f"é”™è¯¯ï¼š{str(e)}"
                    ws.append([filename, error_msg, 0, "å¤±è´¥"])
                    print(f"âŒ [å¼‚å¸¸] {filename}: {e}")

        os.makedirs(os.path.dirname(output_excel), exist_ok=True)
        wb.save(output_excel)
        print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼ç»“æœä¿å­˜è‡³: {output_excel}")

        total_files = len(video_files)
        success_count = sum(1 for row in ws.iter_rows(min_row=2) if row[3].value == "æˆåŠŸ")
        print(f"ğŸ“Š å¤„ç†ç»Ÿè®¡: {success_count}/{total_files} æˆåŠŸ")

    finally:
        if os.path.exists(temp_dir):
            shutil.rmtree(temp_dir, ignore_errors=True)


def main():
    config = {
        "input_folder": r"D:\æ¡Œé¢\åŠ æ²¹ç«™ç´ æ\å®æ‹\input",
        "output_excel": r"D:\æ¡Œé¢\åŠ æ²¹ç«™ç´ æ\å®æ‹\output_optimized.xlsx",
        "model_size": "large",
        "device": "auto",
        "max_processes": None,
    }

    config["device"] = get_optimal_device(config["device"])

    print("ğŸš€ ä¼˜åŒ–ç‰ˆè§†é¢‘è¯­éŸ³è¯†åˆ«å·¥å…·å¯åŠ¨")
    print("=" * 50)
    for key, value in config.items():
        print(f"ğŸ“ {key}: {value}")
    print("=" * 50)

    batch_transcribe_videos(**config)


if __name__ == "__main__":
    mp.set_start_method('spawn', force=True)
    main()
